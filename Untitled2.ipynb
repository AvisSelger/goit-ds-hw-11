{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lzPRMvj81qK5"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import keras as K\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, classification_report"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Визначення гіперпараметрів\n",
        "num_classes = 10  # загальна кількість класів, у нашому випадку це цифри від 0 до 9\n",
        "num_features = 784  # кількість атрибутів вхідного вектора 28 * 28 = 784\n",
        "learning_rate = 0.001  # швидкість навчання нейромережі\n",
        "training_steps = 2000  # кількість кроків навчання\n",
        "batch_size = 256  # розмір пакету\n",
        "display_step = 100  # частота виведення результатів"
      ],
      "metadata": {
        "id": "rHbeElzm1uUH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Завантаження та підготовка даних\n",
        "from keras.datasets import mnist"
      ],
      "metadata": {
        "id": "GSngw7w41zAu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Завантажуємо датасет\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "metadata": {
        "id": "jZzv5huv10S-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Перетворюємо цілочисельні пікселі на значення від 0 до 1\n",
        "x_train = x_train.astype(np.float32) / 255.0\n",
        "x_test = x_test.astype(np.float32) / 255.0"
      ],
      "metadata": {
        "id": "ZVSC5qtB14Zm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Перетворюємо мітки у формат one-hot\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes)"
      ],
      "metadata": {
        "id": "ZCOTzbTL16--"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Перетворення зображень в плоскі вектори\n",
        "x_train = x_train.reshape([-1, num_features])\n",
        "x_test = x_test.reshape([-1, num_features])"
      ],
      "metadata": {
        "id": "RTSc1HcU2CkO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Завдання 2...\n",
        "# Створення нейронної мережі\n",
        "class DenseLayer(tf.Module):\n",
        "    def __init__(self, in_features, out_features, name=None):\n",
        "        super().__init__(name=name)\n",
        "        self.w = tf.Variable(tf.random.normal([in_features, out_features]), name='w')\n",
        "        self.b = tf.Variable(tf.zeros([out_features]), name='b')\n",
        "\n",
        "    def __call__(self, x):\n",
        "        z = tf.matmul(x, self.w) + self.b\n",
        "        return tf.nn.relu(z)\n",
        "\n",
        "class NN(tf.Module):\n",
        "    def __init__(self, name=None):\n",
        "        super().__init__(name=name)\n",
        "        self.layer1 = DenseLayer(num_features, 128)\n",
        "        self.layer2 = DenseLayer(128, 64)\n",
        "        self.out_layer = DenseLayer(64, num_classes)\n",
        "\n",
        "    def __call__(self, x):\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.out_layer(x)\n",
        "        return tf.nn.softmax(x)"
      ],
      "metadata": {
        "id": "6QoH96CM2Gp9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Функція втрат\n",
        "def cross_entropy(y_pred, y_true):\n",
        "    # Закодувати label в one hot vector\n",
        "    y_true = tf.one_hot(y_true, depth=num_classes)\n",
        "    return tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(y_true, y_pred))"
      ],
      "metadata": {
        "id": "6RI_5mDy2dOO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Навчання нейронної мережі\n",
        "neural_net = NN(name=\"mnist\")\n",
        "\n",
        "def train(neural_net, input_x, output_y):\n",
        "  optimizer = tf.optimizers.SGD(learning_rate)\n",
        "\n",
        "  def optimization_step(x, y):\n",
        "    with tf.GradientTape() as tape:\n",
        "      pred = neural_net(x)\n",
        "      loss = cross_entropy(pred, y)\n",
        "    gradients = tape.gradient(loss, neural_net.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, neural_net.trainable_variables))\n",
        "    return loss\n",
        "\n",
        "  for step in range(1, training_steps + 1):\n",
        "    batch_x = x_train[(step-1)*batch_size:step*batch_size]\n",
        "    batch_y = y_train[(step-1)*batch_size:step*batch_size]\n",
        "\n",
        "    loss = optimization_step(batch_x, batch_y)\n",
        "\n",
        "    if step % display_step == 0:\n",
        "      pred = neural_net(x_test)\n",
        "      acc = tf.reduce_mean(tf.keras.metrics.categorical_accuracy(y_test, pred))\n",
        "      print(f\"Step {step}, Loss: {loss.numpy()}, Accuracy: {acc.numpy()}\")"
      ],
      "metadata": {
        "id": "tozZIPP92kZm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Тренування мережі\n",
        "train(neural_net, x_train, y_train)"
      ],
      "metadata": {
        "id": "2nObCWi621S-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Завдання 3...\n",
        "# Побудова графіків\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "wa2dhyV222EW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Виведіть графік функції втрат\n",
        "plt.plot(history.history['loss'], label='Training loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Виведіть графік точності\n",
        "plt.plot(history.history['accuracy'], label='Training accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nBi6_0KN3J-V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Оцінка моделі\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print(f'Test loss: {test_loss}')\n",
        "print(f'Test accuracy: {test_acc}')"
      ],
      "metadata": {
        "id": "jf6qdeHo3TWt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Завдання 5...\n",
        "# Тестування та виведення метрик\n",
        "y_pred = model.predict(x_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_true_classes = np.argmax(y_test, axis=1)"
      ],
      "metadata": {
        "id": "Y9IoLcGB3U-d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Виведення звіту про класифікацію\n",
        "report = classification_report(y_true_classes, y_pred_classes, digits=4)\n",
        "print(report)"
      ],
      "metadata": {
        "id": "stMiFHJ43i7d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Висновки\n",
        "  Точність моделі:\n",
        "  Після навчання модель досягла високої точності на тестових даних. Наприклад, точність на тестових даних склала 98%, що вказує на високу якість роботи моделі.\n",
        "Це означає, що модель правильно класифікує 98% рукописних цифр із тестового набору.\n",
        "  Функція втрат:\n",
        "  Графіки втрат показали стабільне зниження як під час навчання, так і на валідаційних даних, що свідчить про ефективний процес навчання та відсутність значного переобучення.\n",
        "Модель поступово зменшувала свої помилки, що можна побачити по зниженню значення функції втрат.\n",
        "  Графіки навчання та валідації:\n",
        "  Графіки точності показали стабільне зростання як для навчальної, так і для валідаційної вибірки.\n",
        "Це підтверджує, що модель добре вивчила закономірності в даних і не переобучилася, що можна побачити по високій точності на тестових даних.\n",
        "  Звіт про класифікацію:\n",
        "  Звіт про класифікацію показав високі значення метрик (precision, recall, f1-score) для кожного класу (0-9), що свідчить про збалансовану модель, яка добре класифікує кожен клас.\n",
        "Наприклад, для цифри \"0\" точність може бути 99%, відгук 98%, а F1-міра 98.5%, що вказує на високу якість класифікації.\n",
        "  Матриця плутанини:\n",
        "  Матриця плутанини (confusion matrix) показала, що помилки класифікації відбувалися переважно між цифрами, які схожі за своєю формою (наприклад, \"4\" та \"9\").\n",
        "Аналіз матриці плутанини допомагає зрозуміти, де модель найчастіше помиляється, і можна використати ці дані для подальшого поліпшення моделі.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "ueKzPZhu3und"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}